{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXr2z1ORJEJG"
      },
      "source": [
        "## Part - A\n",
        "In this section, we will import our dataset (which can be in any format) and store it as a data frame in a Python object. Furthermore, we will collect data from the dataframes that we will create."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9RXAf9F1jKM"
      },
      "source": [
        "\n",
        "**SRN: BP0272399**\n",
        "\n",
        "**Module : Programming for Data Analysis**\n",
        "\n",
        "**Date: 18 September 2023**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkNjgQo88_n-"
      },
      "source": [
        "Importing the necessary libraries (NumPy and Pandas) for creating and storing data in a dataframe as a Python object with Pandas and performing tabular functions with Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMG0ONc08Vb6"
      },
      "outputs": [],
      "source": [
        "#importing modules\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRk4ARvEH01"
      },
      "source": [
        "### Get data from Excel File\n",
        "We are reading data from the 'Loan Data.xlsx' input file and storing it in the 'data1' object as a data frame. Following that, the data is viewed in tabular format to confirm the basic structure of the dataframe created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qRedWgv9O7H"
      },
      "outputs": [],
      "source": [
        "#read and store XLS data in a variable called data1\n",
        "data1 = pd.read_excel('Loan_Data_XLS_DEMO.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuY4vwV_93LZ"
      },
      "outputs": [],
      "source": [
        "data1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBDnCZnjEBBN"
      },
      "source": [
        "### Extract data from pdf to excel in python\n",
        "We are now installing and importing the tabula.py library in order to use specific functions from this library to convert the tabular data from the 'Loans Database Table.pdf' file to.xlsx format. Later on, I'm storing the data from the excel file in the form of a data frame in the 'data2' object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPSHyvGVVsK8"
      },
      "outputs": [],
      "source": [
        "!pip install tabula-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie90jufF7HLq"
      },
      "source": [
        "###Get data from PDF File\n",
        "The code below is used to extract data from the provided pdf file and then convert the read data into an excel file.<br />\n",
        "```\n",
        "import tabula\n",
        "variable_name = tabula.read_pdf(\"File Path\", pages = 'all')[0]\n",
        "variable_name.to_excel('File Path for excel')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxWfRLGBTltT"
      },
      "outputs": [],
      "source": [
        "#importing modules\n",
        "import tabula\n",
        "\n",
        "#this PDF contains a list\n",
        "convert = tabula.read_pdf(\"Loans_Database_Table_PDF_DEMO.pdf\", pages = 'all')[0]\n",
        "\n",
        "#convert into Excel File.  This will appear in the Google Colab Files Workspace area\n",
        "convert.to_excel('Loans_Database_Table.xlsx')\n",
        "\n",
        "#store from PDF converted XLS data in a variable called data2\n",
        "data2 = pd.read_excel('Loans_Database_Table.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpgYydduDVCI"
      },
      "outputs": [],
      "source": [
        "data2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oamv9MrwVLg"
      },
      "source": [
        "Fetching description of data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8OyBmb77dXY"
      },
      "outputs": [],
      "source": [
        "data1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pCxRH4bwoaI"
      },
      "source": [
        "Fetching description of data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJLMMGFa7bid"
      },
      "outputs": [],
      "source": [
        "data2.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGA0Qdj9xQCk"
      },
      "source": [
        "Checking the data frame for the number of null values in data1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YVT_g2B9-J_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtOV3PS9xQdI"
      },
      "source": [
        "Checking the data frame for the number of null values in data2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG3FgP--DdWy"
      },
      "outputs": [],
      "source": [
        "data2.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTibv6T-EWUi"
      },
      "source": [
        "\n",
        "Merging the two data frames into a single one to make the data processing and analysis easier in the following steps.<br /> <br />\n",
        "Using Pandas Library's **concat()** function, the two data frames - data1 and data2 - are merged into a single data frame - data3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwWpS1JT-B3a"
      },
      "outputs": [],
      "source": [
        "data3 = pd.concat([data2, data1], ignore_index=True)\n",
        "\n",
        "data3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwDuv8VFEQVO"
      },
      "source": [
        "## Part - B:\n",
        "###Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjb_kHeOzULz"
      },
      "source": [
        "Data processing is an important part of data analysis. The data collected from people has many errors and may need to be cleaned up. If you fail to clean up your data, you may have problems analyzing your data and the model you are training with your data may be unreliable.<br /><br />\n",
        "Rectifications to be done on the data are as follows:\n",
        "\n",
        "*   Remove duplicate values\n",
        "*   Remove null and empty values\n",
        "*   Perform sorting\n",
        "<br /><br />\n",
        "\n",
        "**Remove duplicate values**<br />\n",
        "When analyzing data, there can be duplicate values ​​that result in undesired output that undermines our ultimate goal. During  model training, these duplicate values ​​cause overfitting problems. This is a statistical modeling error  that occurs when the function is  too close to the data point (in this case, too many duplicate values).\n",
        "\n",
        "**Remove null and empty values**<br />\n",
        "Null and empty values are treated as 0 by default during data analysis, resulting in unfavourable results, which might be dangerous in the case of business analytics. Null values produce a void in classification type model training challenges like Linear Classifier, Logistic Classifier, Random Forest Classifier, and so on, which may cause confusion for our model  based on its classification functions.\n",
        "\n",
        "**Perform sorting**<br />\n",
        "Sorting is performed based on the primary attributes considered by the analyst for re-arranging the data to simplify deciphering data when considered by the analyst.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tTviGz4zUe7"
      },
      "source": [
        "Checking for any duplicate values in the dataframe that has been produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYdHxqzVFkIX"
      },
      "outputs": [],
      "source": [
        "data3.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDWSb_1kzWXr"
      },
      "source": [
        "Using Loan ID as the primary attribute, sorting the provided data in the dataframe in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylgsZUNqFxwd"
      },
      "outputs": [],
      "source": [
        "data3.sort_values('Loan_ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIW8KyCcH7Fa"
      },
      "source": [
        "###For Model Training\n",
        "The new_data object is constructed according to the assessment handbook's guidelines. It will be utilised in the next sections. Moreover, printing data_for_model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiY_m0iGicj"
      },
      "outputs": [],
      "source": [
        "data_for_model = data3[['Loan_ID','Gender','Married','Dependents','Graduate','Self_Employed','Credit_History','Property_Area','Loan_Status']].copy()\n",
        "data_for_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3-DKBCH5mn"
      },
      "source": [
        "## Part - C\n",
        "###For Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN8rtdYX__Ok"
      },
      "source": [
        "Data analysis is a sequential method of evaluating and illustrating data using logical methods. We sometimes prefer Data Visualization because we can use statistical methods to achieve the desired result.\n",
        "\n",
        "Data analysis is a growing field because it allows for the extraction of vital information from large amounts of data. Knowing about the latest trends, for example, is critical for e-commerce companies like Amazon, which want their customers to use their services more frequently. This is only possible if we can glean useful information from data on products purchased recently by customers at a specific time of year.\n",
        "\n",
        "Furthermore, data analysis is critical for obtaining usable information for training machine learning models. The details we acquire after the study determine which operation we need our ML model to do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xh5wTFHIBHW"
      },
      "outputs": [],
      "source": [
        "analysis = data3[['Loan_ID','Gender','Graduate','Self_Employed','ApplicantIncome','Loan_Status']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OooQn2QKTtu9"
      },
      "outputs": [],
      "source": [
        "analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJs_E7rB05zR"
      },
      "source": [
        "**Solutions for Problem Statements**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLWdG6fjI258"
      },
      "source": [
        "Problem statement 1 - The percentage of female applicants that had their loan approved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaSZMO4lIdGd"
      },
      "outputs": [],
      "source": [
        "statement1 = analysis[analysis['Gender'] == 1]\n",
        "\n",
        "solution1 = statement1[statement1['Loan_Status'] == 'Y'].count()*100/statement1[['Loan_Status']].count()\n",
        "\n",
        "print(f'Percentage: {solution1[\"Loan_Status\"]}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfBxpi7eJPAV"
      },
      "source": [
        "Problem statement 2 - The average income of all applicants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMKrH208Ljmg"
      },
      "outputs": [],
      "source": [
        "solution2 = analysis[['ApplicantIncome']].mean()\n",
        "\n",
        "print(solution2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA6HnYENJQo4"
      },
      "source": [
        "Problem statement 3 - The average income of all applicants that are self-employed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbTadDQ5L0nt"
      },
      "outputs": [],
      "source": [
        "statement3 = analysis[analysis['Self_Employed'] == 1]\n",
        "\n",
        "solution3 = statement3[['ApplicantIncome']].mean()\n",
        "print(solution3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvWxtHolJR0W"
      },
      "source": [
        "Problem statement 4 - The average income of all applicants that are not self-employed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwizOWtpL1Nt"
      },
      "outputs": [],
      "source": [
        "statement4 = analysis[analysis['Self_Employed'] == 0]\n",
        "\n",
        "solution4 = statement4[['ApplicantIncome']].mean()\n",
        "print(solution4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThWmX-2JTaO"
      },
      "source": [
        "Problem statement 5 - The average income of all graduate applicants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NQFj8aqL121"
      },
      "outputs": [],
      "source": [
        "statement5 = analysis[analysis['Graduate'] == 1]\n",
        "\n",
        "solution5 = statement5[['ApplicantIncome']].mean()\n",
        "print(solution5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA5LTr0aJVvz"
      },
      "source": [
        "Problem statement 6 - The percentage of graduate applicants that had their loan status approved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObI_UVyEL2af"
      },
      "outputs": [],
      "source": [
        "statement6 = analysis[analysis['Graduate'] == 1]\n",
        "\n",
        "solution6 = statement6[statement6['Loan_Status'] == 'Y'].count()*100/statement6[['Loan_Status']].count()\n",
        "\n",
        "print(f'Percentage: {solution6[\"Loan_Status\"]}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMURT0-mralD"
      },
      "source": [
        "## Saving the dataframe (data3) as an Excel File (myfile.xlsx) and saving it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SSa6xJmrsrY"
      },
      "outputs": [],
      "source": [
        "#Install XlsxWriter\n",
        "!pip install XlsxWriter\n",
        "# specify a writer fom Pandas\n",
        "writer= pd.ExcelWriter('myfile.xlsx',engine='xlsxwriter')\n",
        "#write the dataframe (data3) to a file\n",
        "data3.to_excel(writer, 'Sheet1')\n",
        "#save this file\n",
        "writer.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPROuZiVONrM"
      },
      "source": [
        "## Part - D\n",
        "This section explains how to train a Machine Learning [ML] model to predict whether a Loan Application will be approved or denied in the future depending on the information provided by the applicant.\n",
        "\n",
        "In order to reduce human effort, a machine learning model is trained to mimic human behaviours. Furthermore, the ML model improves accuracy and rapidly completes the work. We must train an ML model before we can use it. There are three techniques to train an ML model:\n",
        "\n",
        "\n",
        "*   Supervised Learning -> Learning that is supervised\n",
        "*   Unsupervised Learning -> Learning Without Supervision\n",
        "*   Reinforcement Learning -> Learning through Reinforcement\n",
        "\n",
        "**Supervised Learning**\n",
        "\n",
        "It is a type of learning in which big labelled datasets are used to train an ML model. The ML model uses some of the data to train using labelled data, and then the remainder of the data is utilised to test the ML model's accuracy.\n",
        "\n",
        "**Unsupervised Learning**\n",
        "\n",
        "We don't monitor the ML model by giving it with labelled data in this type of learning. The goal of this learning is to detect patterns in the data. To be more specific, unsupervised learning is concerned with getting a machine to detect a pattern in a dataset on its own.\n",
        "\n",
        "**Reinforcement Learning**\n",
        "\n",
        "Reinforcement Learning is a sort of learning in which we can train our model in a similar way to how we would train a pet. We give the model a reward if the outcome is correct, and we don't give the model a reward if the outcome is incorrect. We programmed the computer in such a way that it, like a pet, would attempt to get as many rewards as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOIN_8WGJiL9"
      },
      "source": [
        "### Model Training\n",
        "The ML model is developed using **Supervised Learning** with the data provided with the assessment, while adhering to the guidelines outlined in the assessment manual.\n",
        "\n",
        "Logistic Regression is used to determine whether or not the applications are approved for the loan. Since, given the data we have, logistic regression is the optimal strategy for achieving high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as2ghiqQ6n7E"
      },
      "outputs": [],
      "source": [
        "#Loading Modules\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B2KG6f5Mp_M"
      },
      "source": [
        "Displaying the data in tabular format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zVQQHy6GCeA"
      },
      "outputs": [],
      "source": [
        "data_for_model.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZbad10MzbA"
      },
      "source": [
        "Converting the data frame into X and Y nd-arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9JicEJR6oSl"
      },
      "outputs": [],
      "source": [
        "x_data=data_for_model.iloc[:,1:-1].values\n",
        "y_data=data_for_model.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYiq4hocM-_b"
      },
      "source": [
        "Printing the X array along with its shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6DjPB1Z8gtv"
      },
      "outputs": [],
      "source": [
        "print('X data: ', x_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II8WiDfsNNPl"
      },
      "source": [
        "Printing the Y array along with its shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWd-_O8A8ghS"
      },
      "outputs": [],
      "source": [
        "print('Y data:', y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLAVXtnNP9M"
      },
      "source": [
        "Splitting the X array into x_train and x_test arrays.\n",
        "\n",
        "Similarly, splitting the Y array into y_train and y_test arrays.\n",
        "\n",
        "Here, test data and train data are in the ratio of 70 : 30 for X and Y respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FVbDgU16omS"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.30, random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR_9DFVZN8Hj"
      },
      "source": [
        "We have made a Logistic Regression model and fitted it with x_train and y_train, which is the same as training it. The values from the x_test array are then predicted, and the anticipated values are checked with y_test to produce an accuracy score for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur9m0Ey7-s_B"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "predictions = model.predict(x_test)\n",
        "score = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy: {round(score*100,3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL69nsHnSP-0"
      },
      "source": [
        "We got an accuracy of 85.542% for our ML model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bsRk4ARvEH01"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}